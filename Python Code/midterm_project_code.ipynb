{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2a7f0-77b9-432b-abf3-93d749c8f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "#!pip install mlxtend pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e6aa5a0-de17-40cd-8f79-5108830b228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available databases:\n",
      "1. Amazon\n",
      "2. BestBuy\n",
      "3. KMart\n",
      "4. Nike\n",
      "0. Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number corresponding to the database you'd like to choose (or 0 to exit):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 transactions from Nike.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter support threshold in % (e.g., 10 for 10%):  10\n",
      "Enter confidence threshold in % (e.g., 20 for 20%):  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Nike with support 10.0% and confidence 20.0%...\n",
      "\n",
      "Brute Force Frequent Itemsets:\n",
      "{1: {'Running Shoe': 12, 'Socks': 9, 'Sweatshirts': 16, 'Modern Pants': 11, 'Soccer Shoe': 6, 'Swimming Shirt': 6, 'Rash Guard': 7, 'Dry Fit V-Nick': 4, 'Hoodies': 5, 'Tech Pants': 5}, 2: {('Running Shoe', 'Socks'): 6, ('Running Shoe', 'Sweatshirts'): 9, ('Running Shoe', 'Modern Pants'): 7, ('Socks', 'Sweatshirts'): 8, ('Socks', 'Modern Pants'): 4, ('Sweatshirts', 'Modern Pants'): 9, ('Running Shoe', 'Soccer Shoe'): 4, ('Socks', 'Soccer Shoe'): 2, ('Sweatshirts', 'Soccer Shoe'): 3, ('Modern Pants', 'Soccer Shoe'): 4, ('Sweatshirts', 'Swimming Shirt'): 4, ('Sweatshirts', 'Rash Guard'): 7, ('Soccer Shoe', 'Swimming Shirt'): 4, ('Swimming Shirt', 'Rash Guard'): 2, ('Socks', 'Rash Guard'): 3, ('Socks', 'Hoodies'): 3, ('Sweatshirts', 'Dry Fit V-Nick'): 4, ('Sweatshirts', 'Hoodies'): 4, ('Rash Guard', 'Dry Fit V-Nick'): 3, ('Rash Guard', 'Hoodies'): 4, ('Dry Fit V-Nick', 'Hoodies'): 2, ('Running Shoe', 'Rash Guard'): 2, ('Running Shoe', 'Tech Pants'): 4, ('Sweatshirts', 'Tech Pants'): 3, ('Running Shoe', 'Swimming Shirt'): 4, ('Running Shoe', 'Hoodies'): 2, ('Swimming Shirt', 'Hoodies'): 2, ('Modern Pants', 'Tech Pants'): 2, ('Modern Pants', 'Swimming Shirt'): 3, ('Modern Pants', 'Rash Guard'): 2, ('Modern Pants', 'Dry Fit V-Nick'): 2}}\n",
      "Brute Force Time: 0.0315s\n",
      "\n",
      "Apriori Frequent Itemsets:\n",
      "    support                                           itemsets\n",
      "0      0.20                                   (Dry Fit V-Nick)\n",
      "1      0.25                                          (Hoodies)\n",
      "2      0.55                                     (Modern Pants)\n",
      "3      0.35                                       (Rash Guard)\n",
      "4      0.60                                     (Running Shoe)\n",
      "..      ...                                                ...\n",
      "71     0.10  (Sweatshirts, Modern Pants, Rash Guard, Dry Fi...\n",
      "72     0.10          (Sweatshirts, Rash Guard, Hoodies, Socks)\n",
      "73     0.10  (Soccer Shoe, Modern Pants, Running Shoe, Swea...\n",
      "74     0.15   (Sweatshirts, Modern Pants, Running Shoe, Socks)\n",
      "75     0.10  (Sweatshirts, Modern Pants, Running Shoe, Swim...\n",
      "\n",
      "[76 rows x 2 columns]\n",
      "Apriori Rules:\n",
      "                        antecedents  \\\n",
      "0                  (Dry Fit V-Nick)   \n",
      "1                         (Hoodies)   \n",
      "2                  (Dry Fit V-Nick)   \n",
      "3                      (Rash Guard)   \n",
      "4                  (Dry Fit V-Nick)   \n",
      "..                              ...   \n",
      "267   (Sweatshirts, Swimming Shirt)   \n",
      "268    (Modern Pants, Running Shoe)   \n",
      "269  (Modern Pants, Swimming Shirt)   \n",
      "270  (Running Shoe, Swimming Shirt)   \n",
      "271                (Swimming Shirt)   \n",
      "\n",
      "                                   consequents  antecedent support  \\\n",
      "0                                    (Hoodies)                0.20   \n",
      "1                             (Dry Fit V-Nick)                0.25   \n",
      "2                               (Modern Pants)                0.20   \n",
      "3                             (Dry Fit V-Nick)                0.35   \n",
      "4                                 (Rash Guard)                0.20   \n",
      "..                                         ...                 ...   \n",
      "267               (Modern Pants, Running Shoe)                0.20   \n",
      "268              (Sweatshirts, Swimming Shirt)                0.35   \n",
      "269                (Sweatshirts, Running Shoe)                0.15   \n",
      "270                (Sweatshirts, Modern Pants)                0.20   \n",
      "271  (Sweatshirts, Modern Pants, Running Shoe)                0.30   \n",
      "\n",
      "     consequent support  support  confidence      lift  leverage  conviction  \\\n",
      "0                  0.25     0.10    0.500000  2.000000    0.0500    1.500000   \n",
      "1                  0.20     0.10    0.400000  2.000000    0.0500    1.333333   \n",
      "2                  0.55     0.10    0.500000  0.909091   -0.0100    0.900000   \n",
      "3                  0.20     0.15    0.428571  2.142857    0.0800    1.400000   \n",
      "4                  0.35     0.15    0.750000  2.142857    0.0800    2.600000   \n",
      "..                  ...      ...         ...       ...       ...         ...   \n",
      "267                0.35     0.10    0.500000  1.428571    0.0300    1.300000   \n",
      "268                0.20     0.10    0.285714  1.428571    0.0300    1.120000   \n",
      "269                0.45     0.10    0.666667  1.481481    0.0325    1.650000   \n",
      "270                0.45     0.10    0.500000  1.111111    0.0100    1.100000   \n",
      "271                0.30     0.10    0.333333  1.111111    0.0100    1.050000   \n",
      "\n",
      "     zhangs_metric  \n",
      "0         0.625000  \n",
      "1         0.666667  \n",
      "2        -0.111111  \n",
      "3         0.820513  \n",
      "4         0.666667  \n",
      "..             ...  \n",
      "267       0.375000  \n",
      "268       0.461538  \n",
      "269       0.382353  \n",
      "270       0.125000  \n",
      "271       0.142857  \n",
      "\n",
      "[272 rows x 10 columns]\n",
      "Apriori Time: 0.0120s\n",
      "\n",
      "FP-Growth Frequent Itemsets:\n",
      "    support                                  itemsets\n",
      "0      0.80                             (Sweatshirts)\n",
      "1      0.60                            (Running Shoe)\n",
      "2      0.55                            (Modern Pants)\n",
      "3      0.45                                   (Socks)\n",
      "4      0.30                             (Soccer Shoe)\n",
      "..      ...                                       ...\n",
      "71     0.20                (Running Shoe, Tech Pants)\n",
      "72     0.15                 (Sweatshirts, Tech Pants)\n",
      "73     0.10                (Modern Pants, Tech Pants)\n",
      "74     0.10   (Sweatshirts, Running Shoe, Tech Pants)\n",
      "75     0.10  (Modern Pants, Running Shoe, Tech Pants)\n",
      "\n",
      "[76 rows x 2 columns]\n",
      "FP-Growth Rules:\n",
      "                      antecedents                   consequents  \\\n",
      "0                   (Sweatshirts)                (Running Shoe)   \n",
      "1                  (Running Shoe)                 (Sweatshirts)   \n",
      "2                   (Sweatshirts)                (Modern Pants)   \n",
      "3                  (Modern Pants)                 (Sweatshirts)   \n",
      "4                  (Modern Pants)                (Running Shoe)   \n",
      "..                            ...                           ...   \n",
      "267                  (Tech Pants)   (Sweatshirts, Running Shoe)   \n",
      "268  (Modern Pants, Running Shoe)                  (Tech Pants)   \n",
      "269    (Modern Pants, Tech Pants)                (Running Shoe)   \n",
      "270    (Running Shoe, Tech Pants)                (Modern Pants)   \n",
      "271                  (Tech Pants)  (Modern Pants, Running Shoe)   \n",
      "\n",
      "     antecedent support  consequent support  support  confidence      lift  \\\n",
      "0                  0.80                0.60     0.45    0.562500  0.937500   \n",
      "1                  0.60                0.80     0.45    0.750000  0.937500   \n",
      "2                  0.80                0.55     0.45    0.562500  1.022727   \n",
      "3                  0.55                0.80     0.45    0.818182  1.022727   \n",
      "4                  0.55                0.60     0.35    0.636364  1.060606   \n",
      "..                  ...                 ...      ...         ...       ...   \n",
      "267                0.25                0.45     0.10    0.400000  0.888889   \n",
      "268                0.35                0.25     0.10    0.285714  1.142857   \n",
      "269                0.10                0.60     0.10    1.000000  1.666667   \n",
      "270                0.20                0.55     0.10    0.500000  0.909091   \n",
      "271                0.25                0.35     0.10    0.400000  1.142857   \n",
      "\n",
      "     leverage  conviction  zhangs_metric  \n",
      "0     -0.0300    0.914286      -0.250000  \n",
      "1     -0.0300    0.800000      -0.142857  \n",
      "2      0.0100    1.028571       0.111111  \n",
      "3      0.0100    1.100000       0.049383  \n",
      "4      0.0200    1.100000       0.126984  \n",
      "..        ...         ...            ...  \n",
      "267   -0.0125    0.916667      -0.142857  \n",
      "268    0.0125    1.050000       0.192308  \n",
      "269    0.0400         inf       0.444444  \n",
      "270   -0.0100    0.900000      -0.111111  \n",
      "271    0.0125    1.083333       0.166667  \n",
      "\n",
      "[272 rows x 10 columns]\n",
      "FP-Growth Time: 0.0157s\n",
      "\n",
      "Timing Performance Comparison \n",
      "Brute Force Time: 0.0315s\n",
      "Apriori Time: 0.0120s\n",
      "FP-Growth Time: 0.0157s\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to analyze another dataset? (yes/no):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the program.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import time\n",
    "\n",
    "# Define file paths for the datasets (use raw strings to avoid escape sequence issues)\n",
    "file_paths = {\n",
    "    \"Amazon\": r\"C:\\Users\\rithv\\Downloads\\Amazon_Updated_Transactions.csv\",\n",
    "    \"BestBuy\": r\"C:\\Users\\rithv\\Downloads\\BestBuy_Updated_Transactions.csv\",\n",
    "    \"KMart\": r\"C:\\Users\\rithv\\Downloads\\KMart_Updated_Transactions.csv\",\n",
    "    \"Nike\": r\"C:\\Users\\rithv\\Downloads\\Nike_Updated_Transactions.csv\"\n",
    "}\n",
    "\n",
    "# Load transactions from CSV files\n",
    "def load_transactions(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    transactions = df['Items'].apply(lambda x: x.split(', ')).tolist()\n",
    "    return transactions\n",
    "\n",
    "# Brute Force Method for generating frequent itemsets\n",
    "def generate_frequent_itemsets(transactions, support_threshold):\n",
    "    item_count = {}\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            item_count[item] = item_count.get(item, 0) + 1\n",
    "\n",
    "    frequent_itemsets = {1: {item: count for item, count in item_count.items() if count / len(transactions) >= support_threshold}}\n",
    "\n",
    "    k = 2\n",
    "    while True:\n",
    "        prev_itemsets = list(frequent_itemsets[k - 1].keys())\n",
    "        new_itemsets = list(combinations(prev_itemsets, k))\n",
    "        item_count = {}\n",
    "        for transaction in transactions:\n",
    "            transaction_set = set(transaction)\n",
    "            for itemset in new_itemsets:\n",
    "                if set(itemset).issubset(transaction_set):\n",
    "                    item_count[itemset] = item_count.get(itemset, 0) + 1\n",
    "\n",
    "        frequent_itemsets[k] = {itemset: count for itemset, count in item_count.items() if count / len(transactions) >= support_threshold}\n",
    "        if not frequent_itemsets[k]:\n",
    "            del frequent_itemsets[k]\n",
    "            break\n",
    "        k += 1\n",
    "    return frequent_itemsets\n",
    "\n",
    "# Apriori Algorithm\n",
    "def apriori_algorithm(transactions, support_threshold, confidence_threshold):\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    frequent_itemsets = apriori(df, min_support=support_threshold, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=confidence_threshold)\n",
    "\n",
    "    return frequent_itemsets, rules\n",
    "\n",
    "# FP-Growth Algorithm\n",
    "def fpgrowth_algorithm(transactions, support_threshold, confidence_threshold):\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    frequent_itemsets = fpgrowth(df, min_support=support_threshold, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=confidence_threshold)\n",
    "\n",
    "    return frequent_itemsets, rules\n",
    "\n",
    "# Timing function for comparison\n",
    "def measure_execution_time(algorithm_func, *args):\n",
    "    start_time = time.time()\n",
    "    result = algorithm_func(*args)\n",
    "    end_time = time.time()\n",
    "    return result, end_time - start_time\n",
    "\n",
    "# Main program loop\n",
    "while True:\n",
    "    # Prompt user to select a database or exit\n",
    "    print(\"\\nAvailable databases:\")\n",
    "    for i, name in enumerate(file_paths.keys(), 1):\n",
    "        print(f\"{i}. {name}\")\n",
    "    print(\"0. Exit\")\n",
    "    \n",
    "    choice = int(input(\"Enter the number corresponding to the database you'd like to choose (or 0 to exit): \"))\n",
    "\n",
    "    # Exit the loop if the user chooses 0\n",
    "    if choice == 0:\n",
    "        print(\"Exiting the program.\")\n",
    "        break\n",
    "\n",
    "    # Get the selected database name\n",
    "    db_name = list(file_paths.keys())[choice - 1]\n",
    "\n",
    "    # Load the selected transactions\n",
    "    transactions = load_transactions(file_paths[db_name])\n",
    "    print(f\"Loaded {len(transactions)} transactions from {db_name}.\")\n",
    "\n",
    "    # Prompt user for support and confidence thresholds\n",
    "    support_threshold = float(input(\"Enter support threshold in % (e.g., 10 for 10%): \")) / 100\n",
    "    confidence_threshold = float(input(\"Enter confidence threshold in % (e.g., 20 for 20%): \")) / 100\n",
    "\n",
    "    print(f\"\\nProcessing {db_name} with support {support_threshold * 100}% and confidence {confidence_threshold * 100}%...\")\n",
    "\n",
    "    # Brute Force\n",
    "    bf_result, bf_time = measure_execution_time(generate_frequent_itemsets, transactions, support_threshold)\n",
    "    print(f\"\\nBrute Force Frequent Itemsets:\\n{bf_result}\")\n",
    "    print(f\"Brute Force Time: {bf_time:.4f}s\")\n",
    "\n",
    "    # Apriori\n",
    "    apriori_result, apriori_time = measure_execution_time(apriori_algorithm, transactions, support_threshold, confidence_threshold)\n",
    "    print(f\"\\nApriori Frequent Itemsets:\\n{apriori_result[0]}\")\n",
    "    print(f\"Apriori Rules:\\n{apriori_result[1]}\")\n",
    "    print(f\"Apriori Time: {apriori_time:.4f}s\")\n",
    "\n",
    "    # FP-Growth\n",
    "    fp_result, fp_time = measure_execution_time(fpgrowth_algorithm, transactions, support_threshold, confidence_threshold)\n",
    "    print(f\"\\nFP-Growth Frequent Itemsets:\\n{fp_result[0]}\")\n",
    "    print(f\"FP-Growth Rules:\\n{fp_result[1]}\")\n",
    "    print(f\"FP-Growth Time: {fp_time:.4f}s\")\n",
    "\n",
    "    # Performance summary\n",
    "    print(\"\\nTiming Performance Comparison \")\n",
    "    print(f\"Brute Force Time: {bf_time:.4f}s\")\n",
    "    print(f\"Apriori Time: {apriori_time:.4f}s\")\n",
    "    print(f\"FP-Growth Time: {fp_time:.4f}s\")\n",
    "\n",
    "    # Ask if the user wants to run another analysis\n",
    "    continue_choice = input(\"\\nDo you want to analyze another dataset? (yes/no): \").strip().lower()\n",
    "    if continue_choice != 'yes':\n",
    "        print(\"Exiting the program.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33accfa-eeaa-4a6e-b1c9-7e1711a363a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
